## I. Этапы пайплайна

* data_mart - Создание витрины данных из разных источников: файлы, NoSQL-хранилища, реляционные базы данных.
* filter - Сохранение логов из Kafka в Spark по расписанию, с фильтрацией датасета по признаку. Описание ниже.
* agg - Агрегация данных из потока.
* users_items - Подготовка матрицы users x items по логам из Kafka для прогнозирования пола и возраста.
* features - Подготовка матрицы признаков по логам, лежащим на HDFS, для модели машинного обучения
* mlproject - Обучение модели, инференс модели в real-time
* dashboard - Мониторинг качества работы модели машинного обучения.

### I. Этапы пайплайна
есть наборы данных в разных источниках:

Cassandra – информация о клиентах: uid, пол и возраст.
Elasticsearch – логи посещения интернет-магазина из экосистемы некоего технологического гиганта: страницы товаров, которые открывали посетители магазина, чтобы посмотреть товар или купить его.
HDFS – информация о посещениях сторонних веб-сайтов пользователями, приобретенная у вендора: uid, набор (url, timestamp).
PostgreSQL - информация о тематических категориях веб-сайтов, приобретенная у вендора.
Вам надо агрегировать данные из этих источников в витрину на основе PostgreSQL для отдела маркетинга, чтобы они могли делать свой анализ и таргетировать предложения для клиентов на основе их предпочтений в сети и в магазине.
