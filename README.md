## I. Этапы пайплайна

* data_mart - Создание витрины данных из разных источников: файлы, NoSQL-хранилища, реляционные базы данных
* filter - Сохранение логов из Kafka в Spark по расписанию, с фильтрацией датасета по признаку. Описание ниже
* agg - Агрегация данных из потока в потоке (spark streaming)
* users_items - Подготовка матрицы users x items по логам из Kafka для прогнозирования пола и возраста
* features - Подготовка матрицы признаков по логам, лежащим на HDFS, для модели машинного обучения
* mlproject - Обучение модели, инференс модели в real-time
* dashboard - Мониторинг качества работы модели машинного обучения
